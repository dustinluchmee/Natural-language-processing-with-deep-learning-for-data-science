{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project submission header\n",
    "\n",
    "## Abstractive Summarization of Scientific Papers with BART\n",
    "\n",
    "## Module submission group\n",
    "- Group member 1\n",
    "    - Name: Eric Benton\n",
    "    - Email: emb393@drexel.edu\n",
    "- Group member 2\n",
    "    - Name: Michael Wesner\n",
    "    - Email: mw3344@drexel.edu\n",
    "- Group member 3\n",
    "    - Name: Dustin Luchmee\n",
    "    - Email: dbl47@drexel.edu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code in this notebook modified from https://github.com/huggingface/notebooks/blob/master/examples/summarization.ipynb\n",
    "\n",
    "import torch, json, wandb, nltk, random, datasets\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from datasets import load_dataset, load_metric\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "from transformers import BartForConditionalGeneration, BartTokenizerFast\n",
    "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model and rouge metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"facebook/bart-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Metric(name: \"rouge\", features: {'predictions': Value(dtype='string', id='sequence'), 'references': Value(dtype='string', id='sequence')}, usage: \"\"\"\n",
       "Calculates average rouge scores for a list of hypotheses and references\n",
       "Args:\n",
       "    predictions: list of predictions to score. Each predictions\n",
       "        should be a string with tokens separated by spaces.\n",
       "    references: list of reference for each prediction. Each\n",
       "        reference should be a string with tokens separated by spaces.\n",
       "    rouge_types: A list of rouge types to calculate.\n",
       "        Valid names:\n",
       "        `\"rouge{n}\"` (e.g. `\"rouge1\"`, `\"rouge2\"`) where: {n} is the n-gram based scoring,\n",
       "        `\"rougeL\"`: Longest common subsequence based scoring.\n",
       "        `\"rougeLSum\"`: rougeLsum splits text using `\"\n",
       "\"`.\n",
       "        See details in https://github.com/huggingface/datasets/issues/617\n",
       "    use_stemmer: Bool indicating whether Porter stemmer should be used to strip word suffixes.\n",
       "    use_agregator: Return aggregates if this is set to True\n",
       "Returns:\n",
       "    rouge1: rouge_1 (precision, recall, f1),\n",
       "    rouge2: rouge_2 (precision, recall, f1),\n",
       "    rougeL: rouge_l (precision, recall, f1),\n",
       "    rougeLsum: rouge_lsum (precision, recall, f1)\n",
       "\"\"\", stored examples: 0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and show some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset scientific_papers (/home/mw/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc)\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset('scientific_papers', 'pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 119924\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6633\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['article', 'abstract', 'section_names'],\n",
       "        num_rows: 6658\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_random_elements(dataset, num_examples=1):\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_random_elements(raw_dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tokenizer and see an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizerFast.from_pretrained(\"facebook/bart-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 31414, 6, 42, 65, 3645, 328, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizer example\n",
    "tokenizer(\"Hello, this one sentence!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find average length of training articles and abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abstract_len = 0\n",
    "# article_len = 0\n",
    "\n",
    "# for text in raw_dataset['train']:\n",
    "#     article_len += len(tokenizer.encode(text['article']))\n",
    "#     abstract_len += len(tokenizer.encode(text['abstract']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles = 119924\n",
    "# print(f'Average number of tokens per article: {int(article_len/articles)} and average number of tokens per summary: {int(abstract_len/articles)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average number of tokens per article: 3892 and average number of tokens per summary: 257"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 1024\n",
    "max_target_length = 128\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [doc for doc in examples[\"article\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, padding=True, truncation=True)\n",
    "\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(examples[\"abstract\"], max_length=max_target_length, padding=True, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/mw/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc/cache-1f98a046d8b2dcb8.arrow\n",
      "Loading cached processed dataset at /home/mw/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc/cache-c8f55915ad5db4fe.arrow\n",
      "Loading cached processed dataset at /home/mw/.cache/huggingface/datasets/scientific_papers/pubmed/1.1.1/043e40ed208b8a66ee9e8228c86874946c99d2fc6155a1daee685795851cfdfc/cache-64b1e08e645d5439.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = raw_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['abstract', 'article', 'attention_mask', 'input_ids', 'labels', 'section_names'],\n",
       "        num_rows: 119924\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['abstract', 'article', 'attention_mask', 'input_ids', 'labels', 'section_names'],\n",
       "        num_rows: 6633\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['abstract', 'article', 'attention_mask', 'input_ids', 'labels', 'section_names'],\n",
       "        num_rows: 6658\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train']['labels'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenized_datasets['train']['input_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup training arguments, load model, data collator, and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    \"academic-papers-abstractive-summarization\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=5,\n",
    "    predict_with_generate=True,\n",
    "    fp16=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model, show metrics during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(model,\n",
    "                         args,\n",
    "                         train_dataset=tokenized_datasets[\"train\"],\n",
    "                         eval_dataset=tokenized_datasets[\"validation\"],\n",
    "                         data_collator=data_collator,\n",
    "                         tokenizer=tokenizer,\n",
    "                         compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmw1000\u001b[0m (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.31<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">academic-papers-abstractive-summarization</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/mw1000/huggingface\" target=\"_blank\">https://wandb.ai/mw1000/huggingface</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/mw1000/huggingface/runs/8vv6lhx7\" target=\"_blank\">https://wandb.ai/mw1000/huggingface/runs/8vv6lhx7</a><br/>\n",
       "                Run data is saved locally in <code>/home/mw/Desktop/Drexel classes/NLP deep learning/Project/project-1/wandb/run-20210607_100041-8vv6lhx7</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='199875' max='199875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [199875/199875 13:00:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Rouge1</th>\n",
       "      <th>Rouge2</th>\n",
       "      <th>Rougel</th>\n",
       "      <th>Rougelsum</th>\n",
       "      <th>Gen Len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.073700</td>\n",
       "      <td>1.922067</td>\n",
       "      <td>14.569800</td>\n",
       "      <td>6.718300</td>\n",
       "      <td>12.497300</td>\n",
       "      <td>13.537300</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.937000</td>\n",
       "      <td>1.818550</td>\n",
       "      <td>14.895900</td>\n",
       "      <td>6.959200</td>\n",
       "      <td>12.744300</td>\n",
       "      <td>13.866500</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.881900</td>\n",
       "      <td>1.787529</td>\n",
       "      <td>15.049100</td>\n",
       "      <td>7.006200</td>\n",
       "      <td>12.869600</td>\n",
       "      <td>14.017100</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.809600</td>\n",
       "      <td>1.766275</td>\n",
       "      <td>14.914900</td>\n",
       "      <td>7.080000</td>\n",
       "      <td>12.837000</td>\n",
       "      <td>13.914200</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.746900</td>\n",
       "      <td>1.763582</td>\n",
       "      <td>15.003400</td>\n",
       "      <td>7.124000</td>\n",
       "      <td>12.899100</td>\n",
       "      <td>13.992600</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=199875, training_loss=1.9260239605930465, metrics={'train_runtime': 46843.1812, 'train_samples_per_second': 12.801, 'train_steps_per_second': 4.267, 'total_flos': 5.77838153147351e+17, 'epoch': 5.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TrainOutput\n",
    "\n",
    "global_step=199875\n",
    "\n",
    "training_loss=1.9260239605930465\n",
    "\n",
    "train_runtime': 46843.1812 \n",
    "\n",
    "'train_samples_per_second': 12.801 \n",
    "\n",
    "'train_steps_per_second': 4.267, \n",
    "\n",
    "'total_flos': 5.77838153147351e+17\n",
    "\n",
    "'epoch': 5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "Preds = trainer.predict(test_dataset=tokenized_datasets[\"test\"], \n",
    "                        metric_key_prefix='test', \n",
    "                        max_length=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[    2,     0,  1437, ...,  3625,  3059,     2],\n",
       "       [    2,     0, 14926, ...,    61, 16570,     2],\n",
       "       [    2,     0, 20372, ...,     1,     1,     1],\n",
       "       ...,\n",
       "       [    2,     0,     5, ..., 16117,   479,     2],\n",
       "       [    2,     0,  3618, ...,  2156,     5,     2],\n",
       "       [    2,     0,     5, ..., 50118,   601,     2]]), label_ids=array([[    0,   557,    15, ..., 50118,   333,     2],\n",
       "       [    0,   650,   786, ...,     2,     1,     1],\n",
       "       [    0,  4554,  4832, ..., 13280, 17624,     2],\n",
       "       ...,\n",
       "       [    0,    52,  6190, ...,     5, 23496,     2],\n",
       "       [    0,  4554,  4832, ...,  1437, 50118,     2],\n",
       "       [    0, 33484,  1283, ...,    58,    67,     2]]), metrics={'test_loss': 1.7654982805252075, 'test_rouge1': 42.2238, 'test_rouge2': 18.2209, 'test_rougeL': 27.7722, 'test_rougeLsum': 37.3796, 'test_gen_len': 121.4142, 'test_runtime': 2328.1488, 'test_samples_per_second': 2.86, 'test_steps_per_second': 0.954})"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<s> research on the implications of anxiety in parkinson's disease ( pd ) has been neglected despite its prevalence in nearly 50% of patients and its negative impact on quality of life. \\n previous reports have noted that neuropsychiatric symptoms impair cognitive performance in pd patients ; however, to date, no study has directly compared pd patients with and without anxiety to examine the impact of anxiety on cognitive impairments in pd. \\n this study compared cognitive performance across 50 pd participants with and without anxiety ( 17 pda+ ; 33 pda ), who underwent neurological and neuropsychological assessment. \\n group</s>\""
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:38.989127, resuming normal operation.\n"
     ]
    }
   ],
   "source": [
    "tokenizer.decode(Preds[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s><s> \\n objective. to examine the relationship between anxiety and cognition in parkinson's disease ( pd ) \\n. methods. \\n this cross - sectional study included 17 pd patients with anxiety ( n = 17 ) and thirty - three patients without anxiety, aged between 18 and 30 years, who completed the mini - mental state exam ( mmse ), the hospital anxiety and depression scale ( hads - d > 6 ), and completed a full neuropsychological assessment ( e.g., attention, memory, and executive functioning ). results. in both groups, \\n anxiety was significantly associated</s>\""
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Preds[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.7654982805252075,\n",
       " 'test_rouge1': 42.2238,\n",
       " 'test_rouge2': 18.2209,\n",
       " 'test_rougeL': 27.7722,\n",
       " 'test_rougeLsum': 37.3796,\n",
       " 'test_gen_len': 121.4142,\n",
       " 'test_runtime': 2328.1488,\n",
       " 'test_samples_per_second': 2.86,\n",
       " 'test_steps_per_second': 0.954}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preds[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate predictions with beam search on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_3beams = trainer.predict(test_dataset=tokenized_datasets['test'],\n",
    "                              metric_key_prefix='test',\n",
    "                              max_length=128,\n",
    "                              num_beams=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s><s> \\n background. anxiety and depression are often related and coexist in parkinson's disease ( pd ). \\n however, our current understanding of anxiety and its impact on cognition in pd, as well as its neural basis and best treatment practices, remains meager and lags far behind that of depression. objective. to examine the relationship between anxiety and cognition in patients with pd and to determine the independent effect of anxiety on cognition \\n. methods. a cross - sectional study of 17 pd patients with anxiety and thirty - three pd without anxiety was conducted at the university of sydney.</s>\""
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Pred_3beams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.7654982805252075,\n",
       " 'test_rouge1': 42.275,\n",
       " 'test_rouge2': 18.2406,\n",
       " 'test_rougeL': 27.8668,\n",
       " 'test_rougeLsum': 37.4681,\n",
       " 'test_gen_len': 120.0445,\n",
       " 'test_runtime': 2154.9448,\n",
       " 'test_samples_per_second': 3.09,\n",
       " 'test_steps_per_second': 1.03}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_3beams[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5 Beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_5beams = trainer.predict(test_dataset=tokenized_datasets['test'],\n",
    "                              metric_key_prefix='test',\n",
    "                              max_length=128,\n",
    "                              num_beams=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s><s> \\n background. anxiety and depression are often related and coexist in parkinson's disease ( pd ). \\n however, our current understanding of anxiety and its impact on cognition in pd, as well as its neural basis and best treatment practices, remains meager and lags far behind that of depression. objective. to examine the relationship between anxiety and cognition in patients with pd \\n. methods. a cross - sectional study of 17 pd patients with anxiety and thirty - three patients without anxiety was conducted at the brain and mind centre, university of sydney, in order to determine the independent</s>\""
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Pred_5beams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.7654982805252075,\n",
       " 'test_rouge1': 42.12,\n",
       " 'test_rouge2': 18.1016,\n",
       " 'test_rougeL': 27.5752,\n",
       " 'test_rougeLsum': 37.2314,\n",
       " 'test_gen_len': 122.3542,\n",
       " 'test_runtime': 2522.6649,\n",
       " 'test_samples_per_second': 2.639,\n",
       " 'test_steps_per_second': 0.88}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_5beams[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 Beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_7beams = trainer.predict(test_dataset=tokenized_datasets['test'],\n",
    "                              metric_key_prefix='test',\n",
    "                              max_length=128,\n",
    "                              num_beams=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s><s> \\n background. anxiety and depression are often related and coexist in parkinson's disease ( pd ). \\n however, our current understanding of anxiety and its impact on cognition in pd, as well as its neural basis and best treatment practices, remains meager and lags far behind that of depression. objective. to examine the relationship between anxiety and cognition in patients with pd \\n. methods. a cross - sectional study of 17 pd patients with anxiety and thirty - three patients without anxiety was conducted at the brain and mind centre, university of sydney, in order to determine the independent</s>\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Pred_7beams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.7654982805252075,\n",
       " 'test_rouge1': 41.7882,\n",
       " 'test_rouge2': 17.7992,\n",
       " 'test_rougeL': 27.2814,\n",
       " 'test_rougeLsum': 36.902,\n",
       " 'test_gen_len': 123.0339,\n",
       " 'test_runtime': 2900.4686,\n",
       " 'test_samples_per_second': 2.295,\n",
       " 'test_steps_per_second': 0.765}"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_7beams[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10 Beams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pred_10beams = trainer.predict(test_dataset=tokenized_datasets['test'],\n",
    "                               metric_key_prefix='test',\n",
    "                               max_length=128,\n",
    "                               num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"</s><s> \\n background. anxiety and depression are often related and coexist in parkinson's disease ( pd ). \\n however, our current understanding of anxiety and its impact on cognition in pd, as well as its neural basis and best treatment practices, remains meager and lags far behind that of depression. objective. to examine the independent effect of anxiety on cognition among pd patients with and without anxiety \\n. methods. in this cross - sectional study, \\n 17 patients with anxiety and thirty - three patients without anxiety were recruited from a patient database at the brain and mind centre, university of sy</s>\""
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(Pred_10beams[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.7654982805252075,\n",
       " 'test_rouge1': 41.5606,\n",
       " 'test_rouge2': 17.661,\n",
       " 'test_rougeL': 27.085,\n",
       " 'test_rougeLsum': 36.6851,\n",
       " 'test_gen_len': 123.6877,\n",
       " 'test_runtime': 3689.1254,\n",
       " 'test_samples_per_second': 1.805,\n",
       " 'test_steps_per_second': 0.602}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pred_10beams[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
